import sys
import os
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage

sys.path.append(os.getcwd()) 

load_dotenv() 

from orchestrations.graph import build_graph

def main():
    if not os.getenv("TAVILY_API_KEY"):
        print("âš ï¸  Cáº£nh bÃ¡o: ChÆ°a tháº¥y TAVILY_API_KEY. Web Search cÃ³ thá»ƒ lá»—i.")

    print("ğŸš€ Äang khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng Multi-Agent...")
    graph = build_graph()

    print("\n--- Báº®T Äáº¦U CHAT (GÃµ 'exit' Ä‘á»ƒ thoÃ¡t) ---")
    while True:
        user_input = input("\nğŸ‘¤ Báº¡n: ")
        if user_input.lower() in ["exit", "quit"]:
            print("ğŸ‘‹ Táº¡m biá»‡t!")
            break
        
        if not user_input.strip():
            continue

        print("ğŸ¤– Agent Ä‘ang suy nghÄ©...")
        
        initial_state = {
            "messages": [HumanMessage(content=user_input)],
            "user_query": user_input,
            "enabled_agents": ["web_researcher", "chart_generator", "chart_summarizer", "synthesizer"]
        }

        config = {"recursion_limit": 50}

        try:
            for event in graph.stream(initial_state, config=config): # type: ignore
                for node, values in event.items():
                    print(f"   âš™ï¸  [Node: {node}] Ä‘Ã£ cháº¡y xong.")
                    
                    if "final_answer" in values:
                        print(f"\nâœ… FINAL ANSWER:\n{values['final_answer']}")
                        print("-" * 50)
                        
        except Exception as e:
            print(f"âŒ Lá»—i: {e}")

if __name__ == "__main__":
    main()